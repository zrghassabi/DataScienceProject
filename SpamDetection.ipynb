{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMmSiN4G/YC5I0HBGAc/54j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrghassabi/DataScienceProject/blob/main/SpamDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Classification with Naive Bayes\n",
        "\n",
        "In this notebook, we perform text classification using a Naive Bayes model.\n",
        "We will train the model, evaluate its performance, and use it to make predictions on test data.\n",
        "The goal is to classify messages as either spam (1) or not spam (0)."
      ],
      "metadata": {
        "id": "4WzLD571pG7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h445JE81oz2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Importing Libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "hb4NNixwonbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We start by importing the necessary libraries:\n",
        "\n",
        "pandas for data manipulation.\n",
        "CountVectorizer for converting text data into numerical features.\n",
        "MultinomialNB for our Naive Bayes classifier.\n",
        "f1_score to evaluate model performance.\n"
      ],
      "metadata": {
        "id": "TeSlT7p6pAAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to the extracted file\n",
        "file_path = '/content/sample_data/SMSSpamCollection'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(file_path, sep='\\t', header=None, names=['label', 'text'], encoding='latin1')\n",
        "\n",
        "# Check the first few rows to ensure correct loading\n",
        "print(data.head())\n",
        "\n",
        "# Encode labels\n",
        "data['label'] = data['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the dimensions of the splits\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n"
      ],
      "metadata": {
        "id": "gQb2Ho63ETfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We load the training data from train.csv. The data consists of two columns:\n",
        "\n",
        "text: The message text (input feature).\n",
        "label: The label indicating whether the message is spam (1) or not spam (0)."
      ],
      "metadata": {
        "id": "sV8KQ4UxpRux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Text Vectorization\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "IbHmq5OdpfuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We convert the text data into numerical features using CountVectorizer. This step transforms the text into a matrix of token counts, which can be used for training the model."
      ],
      "metadata": {
        "id": "OkP016Dnpoju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Initialize and Train the Naive Bayes Model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vec, y_train)"
      ],
      "metadata": {
        "id": "dCkn-EQRpnaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We initialize a MultinomialNB model and train it on the vectorized training data (X_train_vec) and labels (y_train)"
      ],
      "metadata": {
        "id": "mhXfIk2GpwMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Evaluate Model Performance on Validation Data\n",
        "X_val_vec = vectorizer.transform(X_val)\n",
        "y_pred_val = nb_model.predict(X_val_vec)\n",
        "f1 = f1_score(y_val, y_pred_val)\n",
        "print(f\"Validation F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "id": "bZywVnCZpzIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Load the test data\n",
        "test_file_path = '/content/sample_data/SMSSpamCollection'  # Update this path to your test file\n",
        "test_data = pd.read_csv(test_file_path, sep='\\t', header=None, names=['label', 'text'], encoding='latin1')\n",
        "\n",
        "# Prepare test data\n",
        "X_test = test_data['text']\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "test_preds = nb_model.predict(X_test_vec)\n",
        "\n",
        "# Create a DataFrame for the submission\n",
        "submission = pd.DataFrame({'label': test_preds})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file created: submission.csv\")\n"
      ],
      "metadata": {
        "id": "z_qGljOyGUMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds"
      ],
      "metadata": {
        "id": "IW6qmdrkGq38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We predict the labels on the validation set and calculate the F1 score. The F1 score is a measure of the modelâ€™s accuracy, considering both precision and recall."
      ],
      "metadata": {
        "id": "hBM-1sZrp8DB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We load the test data from test.csv and transform the text using the same vectorizer that was fitted on the training data. This ensures consistency in feature representation."
      ],
      "metadata": {
        "id": "CDRFmVM_qE7w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation: We create a DataFrame with the predicted labels and save it to submission.csv. This file will be used for evaluation or submission.\n"
      ],
      "metadata": {
        "id": "u6Wj5JrAqUu6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vx8soekzqYvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OAeLJ-4PogMT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Load and prepare test data\n",
        "test_file_path = '/content/sample_data/SMSSpamCollection'  # Update this path to your test file\n",
        "test_data = pd.read_csv(test_file_path, sep='\\t', header=None, names=['label', 'text'], encoding='latin1')\n",
        "\n",
        "# Extract the text column for prediction\n",
        "X_test = test_data['text']\n",
        "y_test_actual = test_data['label']  # Actual target labels for reference\n",
        "\n",
        "# Transform the test data using the same vectorizer\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "test_preds = nb_model.predict(X_test_vec)\n",
        "\n",
        "# Create a DataFrame for the submission\n",
        "submission = pd.DataFrame({\n",
        "    'text': X_test,\n",
        "    'actual_label': y_test_actual.map({'ham': 0, 'spam': 1}),  # Convert actual labels to numerical format\n",
        "    'predicted_label': test_preds\n",
        "})\n",
        "\n",
        "# Map numerical labels back to 'ham' and 'spam' for easier interpretation\n",
        "submission['actual_label'] = submission['actual_label'].map({0: 'ham', 1: 'spam'})\n",
        "submission['predicted_label'] = submission['predicted_label'].map({0: 'ham', 1: 'spam'})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Submission file created: submission.csv\")\n"
      ],
      "metadata": {
        "id": "eR7nzGVhG4I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds"
      ],
      "metadata": {
        "id": "n1YWftaUG9HN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}